{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4dcae2eb",
   "metadata": {},
   "source": [
    "spectrogram saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b52f58b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Processed 0 files\n",
      "✅ Processed 100 files\n",
      "✅ Processed 200 files\n",
      "✅ Processed 300 files\n",
      "✅ Processed 400 files\n",
      "✅ Processed 500 files\n",
      "✅ Processed 600 files\n",
      "✅ Processed 700 files\n",
      "✅ Processed 800 files\n",
      "✅ Processed 900 files\n",
      "✅ Processed 1000 files\n",
      "✅ Processed 1100 files\n",
      "✅ Processed 1200 files\n",
      "✅ Processed 1300 files\n",
      "✅ Processed 1400 files\n",
      "✅ Processed 1500 files\n",
      "✅ Processed 1600 files\n",
      "✅ Processed 1700 files\n",
      "✅ Processed 1800 files\n",
      "✅ Processed 1900 files\n",
      "✅ Processed 2000 files\n",
      "✅ Processed 2100 files\n",
      "✅ Processed 2200 files\n",
      "✅ Processed 2300 files\n",
      "✅ Processed 2400 files\n",
      "✅ Processed 2500 files\n",
      "✅ Processed 2600 files\n",
      "✅ Processed 2700 files\n",
      "✅ Processed 2800 files\n",
      "✅ Processed 2900 files\n",
      "✅ Processed 3000 files\n",
      "✅ Processed 3100 files\n",
      "✅ Processed 3200 files\n",
      "✅ Processed 3300 files\n",
      "✅ Processed 3400 files\n",
      "✅ Processed 3500 files\n",
      "✅ Processed 3600 files\n",
      "✅ Processed 3700 files\n",
      "✅ Processed 3800 files\n",
      "✅ Processed 3900 files\n",
      "✅ Processed 4000 files\n",
      "✅ Processed 4100 files\n",
      "✅ Processed 4200 files\n",
      "✅ Processed 4300 files\n",
      "✅ Processed 4400 files\n",
      "✅ Processed 4500 files\n",
      "✅ Processed 4600 files\n",
      "✅ Processed 4700 files\n",
      "✅ Processed 4800 files\n",
      "✅ Processed 4900 files\n",
      "✅ Processed 5000 files\n",
      "✅ Processed 5100 files\n",
      "✅ Processed 5200 files\n",
      "✅ Processed 5300 files\n",
      "✅ Processed 5400 files\n",
      "✅ Processed 5500 files\n",
      "✅ Processed 5600 files\n",
      "✅ Processed 5700 files\n",
      "✅ Processed 5800 files\n",
      "✅ Processed 5900 files\n",
      "✅ Processed 6000 files\n",
      "✅ Processed 6100 files\n",
      "✅ Processed 6200 files\n",
      "✅ Processed 6300 files\n",
      "✅ Processed 6400 files\n",
      "✅ Processed 6500 files\n",
      "✅ Processed 6600 files\n",
      "✅ Processed 6700 files\n",
      "✅ Processed 6800 files\n",
      "✅ Processed 6900 files\n",
      "✅ Processed 7000 files\n",
      "✅ Processed 7100 files\n",
      "✅ Processed 7200 files\n",
      "✅ Processed 7300 files\n",
      "✅ Processed 7400 files\n",
      "✅ Processed 7500 files\n",
      "✅ Processed 7600 files\n",
      "✅ Processed 7700 files\n",
      "✅ Processed 7800 files\n",
      "✅ Processed 7900 files\n",
      "✅ Processed 8000 files\n",
      "✅ Processed 8100 files\n",
      "✅ Processed 8200 files\n",
      "✅ Processed 8300 files\n",
      "✅ Processed 8400 files\n",
      "✅ Processed 8500 files\n",
      "✅ Processed 8600 files\n",
      "✅ Processed 8700 files\n",
      "✅ Processed 8800 files\n",
      "✅ Processed 8900 files\n",
      "✅ Processed 9000 files\n",
      "✅ Processed 9100 files\n",
      "✅ Processed 9200 files\n",
      "✅ Processed 9300 files\n",
      "✅ Processed 9400 files\n",
      "\n",
      "✅ All spectrograms saved to: mel_specs_augmented\n",
      "📝 Metadata saved to: mel_metadata_augmented.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import torchaudio\n",
    "import pandas as pd\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# ── Settings ──────────────────────────────────────────────\n",
    "SOURCE_DIR = \"Dataset_2025_augmented/Train\"\n",
    "OUTPUT_DIR = \"mel_specs_augmented\"\n",
    "CSV_PATH = \"mel_metadata_augmented.csv\"\n",
    "FIXED_LEN = 112000  # 7 seconds @ 16kHz\n",
    "\n",
    "# ── Mel-spectrogram config ────────────────────────────────\n",
    "mel_transform = torchaudio.transforms.MelSpectrogram(\n",
    "    sample_rate=16000,\n",
    "    n_fft=1024,\n",
    "    hop_length=256,\n",
    "    n_mels=64\n",
    ")\n",
    "db_transform = torchaudio.transforms.AmplitudeToDB()\n",
    "\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "metadata = []\n",
    "\n",
    "# ── Loop through .wav files ───────────────────────────────\n",
    "for i, fname in enumerate(sorted(os.listdir(SOURCE_DIR))):\n",
    "    if not fname.endswith(\".wav\"):\n",
    "        continue\n",
    "\n",
    "    path = os.path.join(SOURCE_DIR, fname)\n",
    "    waveform, sr = torchaudio.load(path)\n",
    "    \n",
    "    # print(f\"\\n📁 Processing file: {fname}\")\n",
    "    # print(f\"🎧 Original sample rate: {sr}\")\n",
    "    # print(f\"🔢 Original waveform shape: {waveform.shape}\")\n",
    "\n",
    "    # Pad or truncate to 7s\n",
    "    if waveform.shape[1] < FIXED_LEN:\n",
    "        waveform = F.pad(waveform, (0, FIXED_LEN - waveform.shape[1]))\n",
    "        # print(f\"📏 Padded to: {waveform.shape}\")\n",
    "    else:\n",
    "        waveform = waveform[:, :FIXED_LEN]\n",
    "        # print(f\"📏 Truncated to: {waveform.shape}\")\n",
    "\n",
    "    # Compute spectrogram\n",
    "    mel = mel_transform(waveform)\n",
    "    spec = db_transform(mel)  # log scale\n",
    "    # spec = spec.unsqueeze(0)  # → [1, 64, time]\n",
    "    # print(f\"📊 Mel shape: {mel.shape} → dB shape: {spec.shape}\")\n",
    "\n",
    "    # Save tensor\n",
    "    save_name = fname.replace(\".wav\", \".pt\")\n",
    "    save_path = os.path.join(OUTPUT_DIR, save_name)\n",
    "    torch.save(spec, save_path)\n",
    "    # print(f\"💾 Saved spectrogram to: {save_path}\")\n",
    "\n",
    "    # Extract label\n",
    "    try:\n",
    "        label = int(fname[0]) - 1\n",
    "    except ValueError:\n",
    "        raise ValueError(f\"❌ Failed to extract label from filename: {fname}\")\n",
    "    # print(f\"🏷️ Parsed label: {label}\")\n",
    "\n",
    "    metadata.append((save_name, label))\n",
    "\n",
    "    if i % 100 == 0:\n",
    "        print(f\"✅ Processed {i} files\")\n",
    "\n",
    "# ── Save metadata CSV ─────────────────────────────────────\n",
    "df = pd.DataFrame(metadata, columns=[\"path\", \"label\"])\n",
    "df.to_csv(CSV_PATH, index=False)\n",
    "print(f\"\\n✅ All spectrograms saved to: {OUTPUT_DIR}\")\n",
    "print(f\"📝 Metadata saved to: {CSV_PATH}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffaa3881",
   "metadata": {},
   "source": [
    "SpectrogramCNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "33ca8f18",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class SelfAttention(nn.Module):\n",
    "    def __init__(self, in_channels):\n",
    "        super().__init__()\n",
    "        self.query = nn.Conv1d(in_channels, in_channels, kernel_size=1)\n",
    "        self.key   = nn.Conv1d(in_channels, in_channels, kernel_size=1)\n",
    "        self.value = nn.Conv1d(in_channels, in_channels, kernel_size=1)\n",
    "        self.scale = in_channels ** 0.5\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x shape: [B, C, F, T] → squeeze F\n",
    "        B, C, F, T = x.shape\n",
    "        x = x.view(B, C * F, T)  # Flatten frequency into channels\n",
    "\n",
    "        Q = self.query(x)\n",
    "        K = self.key(x)\n",
    "        V = self.value(x)\n",
    "\n",
    "        attn = torch.bmm(Q.transpose(1, 2), K) / self.scale\n",
    "        attn = torch.softmax(attn, dim=-1)\n",
    "        out = torch.bmm(attn, V.transpose(1, 2)).transpose(1, 2)\n",
    "\n",
    "        out = out.view(B, C, F, T)  # Reshape back\n",
    "        return out\n",
    "\n",
    "\n",
    "\n",
    "class SpectrogramCNN(nn.Module):\n",
    "    def __init__(self, num_classes=5):\n",
    "        super().__init__()\n",
    "\n",
    "        self.conv_block = nn.Sequential(\n",
    "            nn.Conv2d(1, 32, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32, 32, kernel_size=3, stride=2, padding=1),\n",
    "\n",
    "            nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 64, kernel_size=3, stride=2, padding=1),\n",
    "\n",
    "            nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(128, 128, kernel_size=3, stride=2, padding=1),\n",
    "\n",
    "            nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(256, 256, kernel_size=3, stride=2, padding=1),\n",
    "        )\n",
    "\n",
    "        # Attention block expects input of shape [B, 1024, T]\n",
    "        self.attn = SelfAttention(in_channels=256 * 4)\n",
    "\n",
    "        self.pool = nn.AdaptiveAvgPool2d((4, 4))  # Makes shape consistent before FC\n",
    "\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(256 * 4 * 4, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(512, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv_block(x)      # [B, 256, 4, T]\n",
    "        # x = self.attn(x)            # [B, 256, 4, T] → enhanced via attention\n",
    "        x = self.pool(x)            # [B, 256, 4, 4]\n",
    "        x = self.classifier(x)      # [B, num_classes]\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fd70375a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def train_one_epoch(model, dataloader, optimizer, criterion, device):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for x, y in dataloader:\n",
    "        x, y = x.to(device), y.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        output = model(x)\n",
    "        loss = criterion(output, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        preds = output.argmax(dim=1)\n",
    "        correct += (preds == y).sum().item()\n",
    "        total += y.size(0)\n",
    "\n",
    "    acc = correct / total\n",
    "    avg_loss = running_loss / len(dataloader)\n",
    "    return avg_loss, acc\n",
    "\n",
    "\n",
    "def evaluate(model, dataloader, criterion, device):\n",
    "    model.eval()\n",
    "    total_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for x, y in dataloader:\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            output = model(x)\n",
    "            loss = criterion(output, y)\n",
    "\n",
    "            total_loss += loss.item()\n",
    "            preds = output.argmax(dim=1)\n",
    "            correct += (preds == y).sum().item()\n",
    "            total += y.size(0)\n",
    "\n",
    "    acc = correct / total\n",
    "    avg_loss = total_loss / len(dataloader)\n",
    "    return avg_loss, acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b17005f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(\n",
    "    model,\n",
    "    train_loader,\n",
    "    val_loader,\n",
    "    optimizer,\n",
    "    criterion,\n",
    "    device,\n",
    "    max_epochs=30,\n",
    "    patience=5,\n",
    "    save_path=\"best_model.pt\"\n",
    "):\n",
    "    best_val_acc = 0.0\n",
    "    counter = 0\n",
    "\n",
    "    for epoch in range(max_epochs):\n",
    "        print(f\"\\n🌟 Epoch {epoch+1}/{max_epochs}\")\n",
    "\n",
    "        train_loss, train_acc = train_one_epoch(model, train_loader, optimizer, criterion, device)\n",
    "        val_loss, val_acc = evaluate(model, val_loader, criterion, device)\n",
    "\n",
    "        # 📊 Logging\n",
    "        print(f\"📈 Train Loss: {train_loss:.4f} | Train Acc: {train_acc:.4f}\")\n",
    "        print(f\"📊 Val Loss:   {val_loss:.4f} | Val Acc:   {val_acc:.4f}\")\n",
    "\n",
    "        # 💾 Checkpoint\n",
    "        if val_acc > best_val_acc:\n",
    "            best_val_acc = val_acc\n",
    "            torch.save(model.state_dict(), save_path)\n",
    "            print(f\"💾 Best model saved! (Val Acc: {val_acc:.4f})\")\n",
    "            counter = 0\n",
    "        else:\n",
    "            counter += 1\n",
    "            print(f\"⏳ No improvement. Patience counter: {counter}/{patience}\")\n",
    "\n",
    "        # 🛑 Early stopping\n",
    "        if counter >= patience:\n",
    "            print(\"🛑 Early stopping triggered.\")\n",
    "            break\n",
    "\n",
    "    print(f\"\\n✅ Training complete. Best Val Accuracy: {best_val_acc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63353d14",
   "metadata": {},
   "source": [
    "split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0b35fd0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 Sample batch shape: torch.Size([32, 1, 64, 438])\n",
      "🧷 Sample labels: [4, 1, 3, 4, 1]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "CSV_PATH = \"mel_metadata_augmented.csv\"\n",
    "SPEC_DIR = \"mel_specs_augmented\"\n",
    "\n",
    "# ── Load and split metadata ───────────────────────────────\n",
    "df = pd.read_csv(CSV_PATH)\n",
    "train_df, val_df = train_test_split(df, test_size=0.2, stratify=df['label'], random_state=42)\n",
    "\n",
    "# ── Dataset class for loading .pt spectrograms ─────────────\n",
    "class PrecomputedSpectrogramDataset(Dataset):\n",
    "    def __init__(self, dataframe, spec_dir):\n",
    "        self.df = dataframe.reset_index(drop=True)\n",
    "        self.spec_dir = spec_dir\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        spec_path = os.path.join(self.spec_dir, row['path'])\n",
    "        spectrogram = torch.load(spec_path)  # ← Do NOT squeeze here\n",
    "        label = row['label']\n",
    "        return spectrogram, label\n",
    "\n",
    "# ── Create datasets and loaders ────────────────────────────\n",
    "train_dataset = PrecomputedSpectrogramDataset(train_df, spec_dir=SPEC_DIR)\n",
    "val_dataset   = PrecomputedSpectrogramDataset(val_df,   spec_dir=SPEC_DIR)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader   = DataLoader(val_dataset, batch_size=16)\n",
    "\n",
    "# ── Sanity check on data shape ────────────────────────────\n",
    "sample_x, sample_y = next(iter(train_loader))\n",
    "print(f\"🔍 Sample batch shape: {sample_x.shape}\")  # Expected: [32, 1, 64, T]\n",
    "print(f\"🧷 Sample labels: {sample_y[:5].tolist()}\")\n",
    "\n",
    "model = SpectrogramCNN(num_classes=5)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3, weight_decay=3e-6)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "960d18c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🌟 Epoch 1/100\n",
      "📈 Train Loss: 0.0479 | Train Acc: 0.9888\n",
      "📊 Val Loss:   0.0193 | Val Acc:   0.9968\n",
      "💾 Best model saved! (Val Acc: 0.9968)\n",
      "\n",
      "🌟 Epoch 2/100\n",
      "📈 Train Loss: 0.0387 | Train Acc: 0.9900\n",
      "📊 Val Loss:   0.0103 | Val Acc:   0.9963\n",
      "⏳ No improvement. Patience counter: 1/16\n",
      "\n",
      "🌟 Epoch 3/100\n",
      "📈 Train Loss: 0.0365 | Train Acc: 0.9918\n",
      "📊 Val Loss:   0.0157 | Val Acc:   0.9963\n",
      "⏳ No improvement. Patience counter: 2/16\n",
      "\n",
      "🌟 Epoch 4/100\n",
      "📈 Train Loss: 0.0101 | Train Acc: 0.9970\n",
      "📊 Val Loss:   0.0043 | Val Acc:   0.9979\n",
      "💾 Best model saved! (Val Acc: 0.9979)\n",
      "\n",
      "🌟 Epoch 5/100\n",
      "📈 Train Loss: 0.0118 | Train Acc: 0.9971\n",
      "📊 Val Loss:   0.0102 | Val Acc:   0.9984\n",
      "💾 Best model saved! (Val Acc: 0.9984)\n",
      "\n",
      "🌟 Epoch 6/100\n",
      "📈 Train Loss: 0.0109 | Train Acc: 0.9970\n",
      "📊 Val Loss:   0.0138 | Val Acc:   0.9968\n",
      "⏳ No improvement. Patience counter: 1/16\n",
      "\n",
      "🌟 Epoch 7/100\n",
      "📈 Train Loss: 0.0135 | Train Acc: 0.9961\n",
      "📊 Val Loss:   0.0353 | Val Acc:   0.9953\n",
      "⏳ No improvement. Patience counter: 2/16\n",
      "\n",
      "🌟 Epoch 8/100\n",
      "📈 Train Loss: 0.0208 | Train Acc: 0.9941\n",
      "📊 Val Loss:   0.0722 | Val Acc:   0.9816\n",
      "⏳ No improvement. Patience counter: 3/16\n",
      "\n",
      "🌟 Epoch 9/100\n",
      "📈 Train Loss: 0.0427 | Train Acc: 0.9905\n",
      "📊 Val Loss:   0.0276 | Val Acc:   0.9958\n",
      "⏳ No improvement. Patience counter: 4/16\n",
      "\n",
      "🌟 Epoch 10/100\n",
      "📈 Train Loss: 0.0081 | Train Acc: 0.9970\n",
      "📊 Val Loss:   0.0428 | Val Acc:   0.9953\n",
      "⏳ No improvement. Patience counter: 5/16\n",
      "\n",
      "🌟 Epoch 11/100\n",
      "📈 Train Loss: 0.0371 | Train Acc: 0.9920\n",
      "📊 Val Loss:   0.0742 | Val Acc:   0.9874\n",
      "⏳ No improvement. Patience counter: 6/16\n",
      "\n",
      "🌟 Epoch 12/100\n",
      "📈 Train Loss: 0.0158 | Train Acc: 0.9963\n",
      "📊 Val Loss:   0.0208 | Val Acc:   0.9963\n",
      "⏳ No improvement. Patience counter: 7/16\n",
      "\n",
      "🌟 Epoch 13/100\n",
      "📈 Train Loss: 0.0128 | Train Acc: 0.9970\n",
      "📊 Val Loss:   0.0227 | Val Acc:   0.9942\n",
      "⏳ No improvement. Patience counter: 8/16\n",
      "\n",
      "🌟 Epoch 14/100\n",
      "📈 Train Loss: 0.0227 | Train Acc: 0.9954\n",
      "📊 Val Loss:   0.1470 | Val Acc:   0.9700\n",
      "⏳ No improvement. Patience counter: 9/16\n",
      "\n",
      "🌟 Epoch 15/100\n",
      "📈 Train Loss: 0.0577 | Train Acc: 0.9858\n",
      "📊 Val Loss:   0.1810 | Val Acc:   0.9768\n",
      "⏳ No improvement. Patience counter: 10/16\n",
      "\n",
      "🌟 Epoch 16/100\n",
      "📈 Train Loss: 0.0328 | Train Acc: 0.9928\n",
      "📊 Val Loss:   0.0410 | Val Acc:   0.9921\n",
      "⏳ No improvement. Patience counter: 11/16\n",
      "\n",
      "🌟 Epoch 17/100\n",
      "📈 Train Loss: 0.0155 | Train Acc: 0.9958\n",
      "📊 Val Loss:   0.0287 | Val Acc:   0.9979\n",
      "⏳ No improvement. Patience counter: 12/16\n",
      "\n",
      "🌟 Epoch 18/100\n",
      "📈 Train Loss: 0.0405 | Train Acc: 0.9907\n",
      "📊 Val Loss:   0.0272 | Val Acc:   0.9947\n",
      "⏳ No improvement. Patience counter: 13/16\n",
      "\n",
      "🌟 Epoch 19/100\n",
      "📈 Train Loss: 0.0116 | Train Acc: 0.9962\n",
      "📊 Val Loss:   0.0277 | Val Acc:   0.9979\n",
      "⏳ No improvement. Patience counter: 14/16\n",
      "\n",
      "🌟 Epoch 20/100\n",
      "📈 Train Loss: 0.0043 | Train Acc: 0.9984\n",
      "📊 Val Loss:   0.0337 | Val Acc:   0.9942\n",
      "⏳ No improvement. Patience counter: 15/16\n",
      "\n",
      "🌟 Epoch 21/100\n",
      "📈 Train Loss: 0.0465 | Train Acc: 0.9911\n",
      "📊 Val Loss:   0.0383 | Val Acc:   0.9905\n",
      "⏳ No improvement. Patience counter: 16/16\n",
      "🛑 Early stopping triggered.\n",
      "\n",
      "✅ Training complete. Best Val Accuracy: 0.9984\n"
     ]
    }
   ],
   "source": [
    "train_model(\n",
    "    model=model,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    optimizer=optimizer,\n",
    "    criterion=criterion,\n",
    "    device=device,\n",
    "    max_epochs=100,\n",
    "    patience=16,\n",
    "    save_path=\"best_model_b.pt\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b731b0be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved predictions to submission_b.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import torchaudio\n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# ── Config ────────────────────────────────\n",
    "TEST_WAV_DIR = \"Test set\"\n",
    "MODEL_PATH = \"best_model_b.pt\"\n",
    "OUTPUT_CSV = \"submission_b.csv\"\n",
    "FIXED_LEN = 112000  # 7 seconds at 16kHz\n",
    "\n",
    "# ── Log-Mel Transform ─────────────────────\n",
    "mel_transform = torchaudio.transforms.MelSpectrogram(\n",
    "    sample_rate=16000,\n",
    "    n_fft=1024,\n",
    "    hop_length=256,\n",
    "    n_mels=64\n",
    ")\n",
    "db_transform = torchaudio.transforms.AmplitudeToDB()\n",
    "\n",
    "# ── Test Dataset (on-the-fly spectrogram) ─────────────────\n",
    "class TestWavDataset(Dataset):\n",
    "    def __init__(self, folder_path):\n",
    "        self.folder_path = folder_path\n",
    "        self.files = sorted([f for f in os.listdir(folder_path) if f.endswith(\".wav\")])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        fname = self.files[idx]\n",
    "        path = os.path.join(self.folder_path, fname)\n",
    "\n",
    "        waveform, sr = torchaudio.load(path)\n",
    "\n",
    "        # Pad or truncate to 7s\n",
    "        if waveform.shape[1] < FIXED_LEN:\n",
    "            pad_len = FIXED_LEN - waveform.shape[1]\n",
    "            waveform = F.pad(waveform, (0, pad_len))\n",
    "        else:\n",
    "            waveform = waveform[:, :FIXED_LEN]\n",
    "\n",
    "        # Convert to log-mel spectrogram\n",
    "        mel = mel_transform(waveform)\n",
    "        mel_db = db_transform(mel)\n",
    "        # mel_db = mel_db.unsqueeze(0)  # shape: [1, 64, T]\n",
    "\n",
    "        file_id = os.path.splitext(fname)[0]\n",
    "        return mel_db, file_id\n",
    "\n",
    "# ── Run prediction and save submission ─────\n",
    "def run_test():\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    model = SpectrogramCNN(num_classes=5)\n",
    "    model.load_state_dict(torch.load(MODEL_PATH, map_location=device))\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    dataset = TestWavDataset(TEST_WAV_DIR)\n",
    "    loader = DataLoader(dataset, batch_size=32)\n",
    "\n",
    "    predictions = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch, ids in loader:\n",
    "            batch = batch.to(device)\n",
    "            outputs = model(batch)\n",
    "            preds = torch.argmax(outputs, dim=1) + 1  # [0–4] → [1–5]\n",
    "            predictions.extend(zip(ids, preds.cpu().numpy()))\n",
    "\n",
    "    df = pd.DataFrame(predictions, columns=[\"Id\", \"label\"])\n",
    "    df.to_csv(OUTPUT_CSV, index=False)\n",
    "    print(f\"✅ Saved predictions to {OUTPUT_CSV}\")\n",
    "\n",
    "# ── Entry Point ───────────────────────────\n",
    "if __name__ == \"__main__\":\n",
    "    run_test()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c61b6f28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved predictions to results_modelB\\detailed_predictions_modelB.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hiwa\\AppData\\Local\\Temp\\ipykernel_30400\\3715652626.py:75: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  combo_acc = df.groupby(\"group_sex\").apply(lambda x: (x.label == x.true).mean()).reset_index(name=\"accuracy\")\n",
      "C:\\Users\\hiwa\\AppData\\Local\\Temp\\ipykernel_30400\\3715652626.py:77: FutureWarning: \n",
      "\n",
      "Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.\n",
      "\n",
      "  sns.barplot(data=combo_acc, x=\"group_sex\", y=\"accuracy\", palette=\"viridis\")\n",
      "C:\\Users\\hiwa\\AppData\\Local\\Temp\\ipykernel_30400\\3715652626.py:82: UserWarning: Glyph 128269 (\\N{LEFT-POINTING MAGNIFYING GLASS}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "C:\\Users\\hiwa\\AppData\\Local\\Temp\\ipykernel_30400\\3715652626.py:83: UserWarning: Glyph 128269 (\\N{LEFT-POINTING MAGNIFYING GLASS}) missing from font(s) DejaVu Sans.\n",
      "  plt.savefig(os.path.join(RESULT_DIR, \"accuracy_by_group_sex_modelB.png\"))\n",
      "C:\\Users\\hiwa\\AppData\\Local\\Temp\\ipykernel_30400\\3715652626.py:86: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  group_acc = df.groupby(\"group\").apply(lambda x: (x.label == x.true).mean()).reset_index(name=\"accuracy\")\n",
      "C:\\Users\\hiwa\\AppData\\Local\\Temp\\ipykernel_30400\\3715652626.py:88: FutureWarning: \n",
      "\n",
      "Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.\n",
      "\n",
      "  sns.barplot(data=group_acc, x=\"group\", y=\"accuracy\", palette=\"Blues_d\")\n",
      "C:\\Users\\hiwa\\AppData\\Local\\Temp\\ipykernel_30400\\3715652626.py:93: UserWarning: Glyph 127919 (\\N{DIRECT HIT}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "C:\\Users\\hiwa\\AppData\\Local\\Temp\\ipykernel_30400\\3715652626.py:94: UserWarning: Glyph 127919 (\\N{DIRECT HIT}) missing from font(s) DejaVu Sans.\n",
      "  plt.savefig(os.path.join(RESULT_DIR, \"accuracy_by_group_modelB.png\"))\n",
      "C:\\Users\\hiwa\\AppData\\Local\\Temp\\ipykernel_30400\\3715652626.py:97: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  sex_acc = df.groupby(\"sex\").apply(lambda x: (x.label == x.true).mean()).reset_index(name=\"accuracy\")\n",
      "C:\\Users\\hiwa\\AppData\\Local\\Temp\\ipykernel_30400\\3715652626.py:99: FutureWarning: \n",
      "\n",
      "Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.\n",
      "\n",
      "  sns.barplot(data=sex_acc, x=\"sex\", y=\"accuracy\", palette=\"Set2\")\n",
      "C:\\Users\\hiwa\\AppData\\Local\\Temp\\ipykernel_30400\\3715652626.py:104: UserWarning: Glyph 129489 (\\N{ADULT}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "C:\\Users\\hiwa\\AppData\\Local\\Temp\\ipykernel_30400\\3715652626.py:104: UserWarning: Glyph 129309 (\\N{HANDSHAKE}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "C:\\Users\\hiwa\\AppData\\Local\\Temp\\ipykernel_30400\\3715652626.py:105: UserWarning: Glyph 129489 (\\N{ADULT}) missing from font(s) DejaVu Sans.\n",
      "  plt.savefig(os.path.join(RESULT_DIR, \"accuracy_by_sex_modelB.png\"))\n",
      "C:\\Users\\hiwa\\AppData\\Local\\Temp\\ipykernel_30400\\3715652626.py:105: UserWarning: Glyph 129309 (\\N{HANDSHAKE}) missing from font(s) DejaVu Sans.\n",
      "  plt.savefig(os.path.join(RESULT_DIR, \"accuracy_by_sex_modelB.png\"))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📊 All results saved in results_modelB\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import torchaudio\n",
    "import pandas as pd\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# ── Config ────────────────────────────────\n",
    "DATA_DIR = \"Dataset_2025/Train\"\n",
    "MODEL_PATH = \"best_model_b.pt\"\n",
    "RESULT_DIR = \"results_modelB\"\n",
    "FIXED_LEN = 112000  # 7 seconds at 16kHz\n",
    "os.makedirs(RESULT_DIR, exist_ok=True)\n",
    "\n",
    "# ── Log-Mel Transform ─────────────────────\n",
    "mel_transform = torchaudio.transforms.MelSpectrogram(\n",
    "    sample_rate=16000,\n",
    "    n_fft=1024,\n",
    "    hop_length=256,\n",
    "    n_mels=64\n",
    ")\n",
    "db_transform = torchaudio.transforms.AmplitudeToDB()\n",
    "\n",
    "# ── Dataset ───────────────────────────────\n",
    "class SpectrogramDataset(Dataset):\n",
    "    def __init__(self, folder_path):\n",
    "        self.folder_path = folder_path\n",
    "        self.files = sorted([f for f in os.listdir(folder_path) if f.endswith(\".wav\")])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        fname = self.files[idx]\n",
    "        path = os.path.join(self.folder_path, fname)\n",
    "\n",
    "        waveform, sr = torchaudio.load(path)\n",
    "        if waveform.shape[1] < FIXED_LEN:\n",
    "            pad_len = FIXED_LEN - waveform.shape[1]\n",
    "            waveform = F.pad(waveform, (0, pad_len))\n",
    "        else:\n",
    "            waveform = waveform[:, :FIXED_LEN]\n",
    "\n",
    "        mel = mel_transform(waveform)\n",
    "        mel_db = db_transform(mel)\n",
    "\n",
    "        file_id = os.path.splitext(fname)[0]\n",
    "        group, sex = file_id[0], file_id[1]\n",
    "        true_label = int(group)\n",
    "        return mel_db, file_id, true_label, group, sex\n",
    "\n",
    "# ── Evaluation ────────────────────────────\n",
    "def evaluate(model, loader, device):\n",
    "    model.eval()\n",
    "    all_preds, all_trues, meta = [], [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch, ids, labels, groups, sexes in loader:\n",
    "            batch = batch.to(device)\n",
    "            outputs = model(batch)\n",
    "            preds = torch.argmax(outputs, dim=1) + 1\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_trues.extend(labels.numpy())\n",
    "            meta.extend(zip(ids, groups, sexes))\n",
    "\n",
    "    return all_preds, all_trues, meta\n",
    "\n",
    "# ── Plots ─────────────────────────────────\n",
    "def plot_group_sex_accuracy(df):\n",
    "    df[\"group_sex\"] = df[\"group\"] + df[\"sex\"]\n",
    "\n",
    "    combo_acc = df.groupby(\"group_sex\").apply(lambda x: (x.label == x.true).mean()).reset_index(name=\"accuracy\")\n",
    "    plt.figure(figsize=(8, 5))\n",
    "    sns.barplot(data=combo_acc, x=\"group_sex\", y=\"accuracy\", palette=\"viridis\")\n",
    "    plt.title(\"🔍 Accuracy by Group and Sex\")\n",
    "    plt.ylabel(\"Accuracy\")\n",
    "    plt.ylim(0, 1)\n",
    "    plt.grid(axis=\"y\", linestyle=\"--\", alpha=0.4)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(RESULT_DIR, \"accuracy_by_group_sex_modelB.png\"))\n",
    "    plt.close()\n",
    "\n",
    "    group_acc = df.groupby(\"group\").apply(lambda x: (x.label == x.true).mean()).reset_index(name=\"accuracy\")\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    sns.barplot(data=group_acc, x=\"group\", y=\"accuracy\", palette=\"Blues_d\")\n",
    "    plt.title(\"🎯 Accuracy by Group\")\n",
    "    plt.ylabel(\"Accuracy\")\n",
    "    plt.ylim(0, 1)\n",
    "    plt.grid(axis=\"y\", linestyle=\"--\", alpha=0.4)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(RESULT_DIR, \"accuracy_by_group_modelB.png\"))\n",
    "    plt.close()\n",
    "\n",
    "    sex_acc = df.groupby(\"sex\").apply(lambda x: (x.label == x.true).mean()).reset_index(name=\"accuracy\")\n",
    "    plt.figure(figsize=(5, 4))\n",
    "    sns.barplot(data=sex_acc, x=\"sex\", y=\"accuracy\", palette=\"Set2\")\n",
    "    plt.title(\"🧑‍🤝‍🧑 Accuracy by Sex\")\n",
    "    plt.ylabel(\"Accuracy\")\n",
    "    plt.ylim(0, 1)\n",
    "    plt.grid(axis=\"y\", linestyle=\"--\", alpha=0.4)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(RESULT_DIR, \"accuracy_by_sex_modelB.png\"))\n",
    "    plt.close()\n",
    "\n",
    "def plot_confusion_matrix(y_true, y_pred):\n",
    "    cm = confusion_matrix(y_true, y_pred, labels=[1,2,3,4,5])\n",
    "    plt.figure(figsize=(6, 5))\n",
    "    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=[1,2,3,4,5], yticklabels=[1,2,3,4,5])\n",
    "    plt.title(\"Confusion Matrix\")\n",
    "    plt.xlabel(\"Predicted\")\n",
    "    plt.ylabel(\"True\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(RESULT_DIR, \"confusion_matrix_modelB.png\"))\n",
    "    plt.close()\n",
    "\n",
    "# ── Main ─────────────────────────────────\n",
    "def run_full_evaluation():\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "    model = SpectrogramCNN(num_classes=5)\n",
    "    model.load_state_dict(torch.load(MODEL_PATH, map_location=device))\n",
    "    model.to(device)\n",
    "\n",
    "    dataset = SpectrogramDataset(DATA_DIR)\n",
    "    loader = DataLoader(dataset, batch_size=32)\n",
    "\n",
    "    preds, trues, meta = evaluate(model, loader, device)\n",
    "\n",
    "    df = pd.DataFrame(meta, columns=[\"Id\", \"group\", \"sex\"])\n",
    "    df[\"label\"] = preds\n",
    "    df[\"true\"] = trues\n",
    "    df.to_csv(os.path.join(RESULT_DIR, \"detailed_predictions_modelB.csv\"), index=False)\n",
    "    print(f\"✅ Saved predictions to {os.path.join(RESULT_DIR, 'detailed_predictions_modelB.csv')}\")\n",
    "\n",
    "    plot_group_sex_accuracy(df)\n",
    "    plot_confusion_matrix(df[\"true\"], df[\"label\"])\n",
    "    print(f\"📊 All results saved in {RESULT_DIR}\")\n",
    "\n",
    "# ── Run ──────────────────────────────────\n",
    "if __name__ == \"__main__\":\n",
    "    run_full_evaluation()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42a2d3dc",
   "metadata": {},
   "source": [
    "model b2: this was to see if lowering the learning rate would help the model acheive 1 R2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0d235eb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🌟 Epoch 1/100\n",
      "📈 Train Loss: 0.0235 | Train Acc: 0.9943\n",
      "📊 Val Loss:   0.1094 | Val Acc:   0.9837\n",
      "💾 Best model saved! (Val Acc: 0.9837)\n",
      "\n",
      "🌟 Epoch 2/100\n",
      "📈 Train Loss: 0.0429 | Train Acc: 0.9917\n",
      "📊 Val Loss:   0.0240 | Val Acc:   0.9958\n",
      "💾 Best model saved! (Val Acc: 0.9958)\n",
      "\n",
      "🌟 Epoch 3/100\n",
      "📈 Train Loss: 0.0081 | Train Acc: 0.9982\n",
      "📊 Val Loss:   0.0179 | Val Acc:   0.9979\n",
      "💾 Best model saved! (Val Acc: 0.9979)\n",
      "\n",
      "🌟 Epoch 4/100\n",
      "📈 Train Loss: 0.0284 | Train Acc: 0.9947\n",
      "📊 Val Loss:   0.0397 | Val Acc:   0.9905\n",
      "⏳ No improvement. Patience counter: 1/16\n",
      "\n",
      "🌟 Epoch 5/100\n",
      "📈 Train Loss: 0.0125 | Train Acc: 0.9971\n",
      "📊 Val Loss:   0.0923 | Val Acc:   0.9905\n",
      "⏳ No improvement. Patience counter: 2/16\n",
      "\n",
      "🌟 Epoch 6/100\n",
      "📈 Train Loss: 0.0414 | Train Acc: 0.9926\n",
      "📊 Val Loss:   0.0116 | Val Acc:   0.9974\n",
      "⏳ No improvement. Patience counter: 3/16\n",
      "\n",
      "🌟 Epoch 7/100\n",
      "📈 Train Loss: 0.0084 | Train Acc: 0.9980\n",
      "📊 Val Loss:   0.0256 | Val Acc:   0.9958\n",
      "⏳ No improvement. Patience counter: 4/16\n",
      "\n",
      "🌟 Epoch 8/100\n",
      "📈 Train Loss: 0.0362 | Train Acc: 0.9947\n",
      "📊 Val Loss:   0.0123 | Val Acc:   0.9968\n",
      "⏳ No improvement. Patience counter: 5/16\n",
      "\n",
      "🌟 Epoch 9/100\n",
      "📈 Train Loss: 0.0102 | Train Acc: 0.9963\n",
      "📊 Val Loss:   0.0188 | Val Acc:   0.9953\n",
      "⏳ No improvement. Patience counter: 6/16\n",
      "\n",
      "🌟 Epoch 10/100\n",
      "📈 Train Loss: 0.0232 | Train Acc: 0.9946\n",
      "📊 Val Loss:   0.0168 | Val Acc:   0.9974\n",
      "⏳ No improvement. Patience counter: 7/16\n",
      "\n",
      "🌟 Epoch 11/100\n",
      "📈 Train Loss: 0.0107 | Train Acc: 0.9961\n",
      "📊 Val Loss:   0.0275 | Val Acc:   0.9953\n",
      "⏳ No improvement. Patience counter: 8/16\n",
      "\n",
      "🌟 Epoch 12/100\n",
      "📈 Train Loss: 0.0236 | Train Acc: 0.9945\n",
      "📊 Val Loss:   0.0230 | Val Acc:   0.9968\n",
      "⏳ No improvement. Patience counter: 9/16\n",
      "\n",
      "🌟 Epoch 13/100\n",
      "📈 Train Loss: 0.0091 | Train Acc: 0.9978\n",
      "📊 Val Loss:   0.0205 | Val Acc:   0.9953\n",
      "⏳ No improvement. Patience counter: 10/16\n",
      "\n",
      "🌟 Epoch 14/100\n",
      "📈 Train Loss: 0.0047 | Train Acc: 0.9984\n",
      "📊 Val Loss:   0.0154 | Val Acc:   0.9963\n",
      "⏳ No improvement. Patience counter: 11/16\n",
      "\n",
      "🌟 Epoch 15/100\n",
      "📈 Train Loss: 0.0031 | Train Acc: 0.9992\n",
      "📊 Val Loss:   0.0188 | Val Acc:   0.9958\n",
      "⏳ No improvement. Patience counter: 12/16\n",
      "\n",
      "🌟 Epoch 16/100\n",
      "📈 Train Loss: 0.0363 | Train Acc: 0.9917\n",
      "📊 Val Loss:   0.0411 | Val Acc:   0.9926\n",
      "⏳ No improvement. Patience counter: 13/16\n",
      "\n",
      "🌟 Epoch 17/100\n",
      "📈 Train Loss: 0.0297 | Train Acc: 0.9930\n",
      "📊 Val Loss:   0.0261 | Val Acc:   0.9937\n",
      "⏳ No improvement. Patience counter: 14/16\n",
      "\n",
      "🌟 Epoch 18/100\n",
      "📈 Train Loss: 0.0191 | Train Acc: 0.9947\n",
      "📊 Val Loss:   0.0281 | Val Acc:   0.9958\n",
      "⏳ No improvement. Patience counter: 15/16\n",
      "\n",
      "🌟 Epoch 19/100\n",
      "📈 Train Loss: 0.0166 | Train Acc: 0.9970\n",
      "📊 Val Loss:   0.0211 | Val Acc:   0.9958\n",
      "⏳ No improvement. Patience counter: 16/16\n",
      "🛑 Early stopping triggered.\n",
      "\n",
      "✅ Training complete. Best Val Accuracy: 0.9979\n"
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3, weight_decay=1e-6)\n",
    "\n",
    "train_model(\n",
    "    model=model,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    optimizer=optimizer,\n",
    "    criterion=criterion,\n",
    "    device=device,\n",
    "    max_epochs=100,\n",
    "    patience=16,\n",
    "    save_path=\"best_model_b2.pt\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1ad898c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved predictions to submission_b2.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import torchaudio\n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# ── Config ────────────────────────────────\n",
    "TEST_WAV_DIR = \"Test set\"\n",
    "MODEL_PATH = \"best_model_b2.pt\"\n",
    "OUTPUT_CSV = \"submission_b2.csv\"\n",
    "FIXED_LEN = 112000  # 7 seconds at 16kHz\n",
    "\n",
    "# ── Log-Mel Transform ─────────────────────\n",
    "mel_transform = torchaudio.transforms.MelSpectrogram(\n",
    "    sample_rate=16000,\n",
    "    n_fft=1024,\n",
    "    hop_length=256,\n",
    "    n_mels=64\n",
    ")\n",
    "db_transform = torchaudio.transforms.AmplitudeToDB()\n",
    "\n",
    "# ── Test Dataset (on-the-fly spectrogram) ─────────────────\n",
    "class TestWavDataset(Dataset):\n",
    "    def __init__(self, folder_path):\n",
    "        self.folder_path = folder_path\n",
    "        self.files = sorted([f for f in os.listdir(folder_path) if f.endswith(\".wav\")])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        fname = self.files[idx]\n",
    "        path = os.path.join(self.folder_path, fname)\n",
    "\n",
    "        waveform, sr = torchaudio.load(path)\n",
    "\n",
    "        # Pad or truncate to 7s\n",
    "        if waveform.shape[1] < FIXED_LEN:\n",
    "            pad_len = FIXED_LEN - waveform.shape[1]\n",
    "            waveform = F.pad(waveform, (0, pad_len))\n",
    "        else:\n",
    "            waveform = waveform[:, :FIXED_LEN]\n",
    "\n",
    "        # Convert to log-mel spectrogram\n",
    "        mel = mel_transform(waveform)\n",
    "        mel_db = db_transform(mel)\n",
    "        # mel_db = mel_db.unsqueeze(0)  # shape: [1, 64, T]\n",
    "\n",
    "        file_id = os.path.splitext(fname)[0]\n",
    "        return mel_db, file_id\n",
    "\n",
    "# ── Run prediction and save submission ─────\n",
    "def run_test():\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    model = SpectrogramCNN(num_classes=5)\n",
    "    model.load_state_dict(torch.load(MODEL_PATH, map_location=device))\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    dataset = TestWavDataset(TEST_WAV_DIR)\n",
    "    loader = DataLoader(dataset, batch_size=32)\n",
    "\n",
    "    predictions = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch, ids in loader:\n",
    "            batch = batch.to(device)\n",
    "            outputs = model(batch)\n",
    "            preds = torch.argmax(outputs, dim=1) + 1  # [0–4] → [1–5]\n",
    "            predictions.extend(zip(ids, preds.cpu().numpy()))\n",
    "\n",
    "    df = pd.DataFrame(predictions, columns=[\"Id\", \"label\"])\n",
    "    df.to_csv(OUTPUT_CSV, index=False)\n",
    "    print(f\"✅ Saved predictions to {OUTPUT_CSV}\")\n",
    "\n",
    "# ── Entry Point ───────────────────────────\n",
    "if __name__ == \"__main__\":\n",
    "    run_test()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "13b2921a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved predictions to results_modelB2\\detailed_predictions_modelB.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hiwa\\AppData\\Local\\Temp\\ipykernel_30400\\3700240753.py:75: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  combo_acc = df.groupby(\"group_sex\").apply(lambda x: (x.label == x.true).mean()).reset_index(name=\"accuracy\")\n",
      "C:\\Users\\hiwa\\AppData\\Local\\Temp\\ipykernel_30400\\3700240753.py:77: FutureWarning: \n",
      "\n",
      "Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.\n",
      "\n",
      "  sns.barplot(data=combo_acc, x=\"group_sex\", y=\"accuracy\", palette=\"viridis\")\n",
      "C:\\Users\\hiwa\\AppData\\Local\\Temp\\ipykernel_30400\\3700240753.py:82: UserWarning: Glyph 128269 (\\N{LEFT-POINTING MAGNIFYING GLASS}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "C:\\Users\\hiwa\\AppData\\Local\\Temp\\ipykernel_30400\\3700240753.py:83: UserWarning: Glyph 128269 (\\N{LEFT-POINTING MAGNIFYING GLASS}) missing from font(s) DejaVu Sans.\n",
      "  plt.savefig(os.path.join(RESULT_DIR, \"accuracy_by_group_sex_modelB.png\"))\n",
      "C:\\Users\\hiwa\\AppData\\Local\\Temp\\ipykernel_30400\\3700240753.py:86: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  group_acc = df.groupby(\"group\").apply(lambda x: (x.label == x.true).mean()).reset_index(name=\"accuracy\")\n",
      "C:\\Users\\hiwa\\AppData\\Local\\Temp\\ipykernel_30400\\3700240753.py:88: FutureWarning: \n",
      "\n",
      "Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.\n",
      "\n",
      "  sns.barplot(data=group_acc, x=\"group\", y=\"accuracy\", palette=\"Blues_d\")\n",
      "C:\\Users\\hiwa\\AppData\\Local\\Temp\\ipykernel_30400\\3700240753.py:93: UserWarning: Glyph 127919 (\\N{DIRECT HIT}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "C:\\Users\\hiwa\\AppData\\Local\\Temp\\ipykernel_30400\\3700240753.py:94: UserWarning: Glyph 127919 (\\N{DIRECT HIT}) missing from font(s) DejaVu Sans.\n",
      "  plt.savefig(os.path.join(RESULT_DIR, \"accuracy_by_group_modelB.png\"))\n",
      "C:\\Users\\hiwa\\AppData\\Local\\Temp\\ipykernel_30400\\3700240753.py:97: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  sex_acc = df.groupby(\"sex\").apply(lambda x: (x.label == x.true).mean()).reset_index(name=\"accuracy\")\n",
      "C:\\Users\\hiwa\\AppData\\Local\\Temp\\ipykernel_30400\\3700240753.py:99: FutureWarning: \n",
      "\n",
      "Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.\n",
      "\n",
      "  sns.barplot(data=sex_acc, x=\"sex\", y=\"accuracy\", palette=\"Set2\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📊 All results saved in results_modelB2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hiwa\\AppData\\Local\\Temp\\ipykernel_30400\\3700240753.py:104: UserWarning: Glyph 129489 (\\N{ADULT}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "C:\\Users\\hiwa\\AppData\\Local\\Temp\\ipykernel_30400\\3700240753.py:104: UserWarning: Glyph 129309 (\\N{HANDSHAKE}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "C:\\Users\\hiwa\\AppData\\Local\\Temp\\ipykernel_30400\\3700240753.py:105: UserWarning: Glyph 129489 (\\N{ADULT}) missing from font(s) DejaVu Sans.\n",
      "  plt.savefig(os.path.join(RESULT_DIR, \"accuracy_by_sex_modelB.png\"))\n",
      "C:\\Users\\hiwa\\AppData\\Local\\Temp\\ipykernel_30400\\3700240753.py:105: UserWarning: Glyph 129309 (\\N{HANDSHAKE}) missing from font(s) DejaVu Sans.\n",
      "  plt.savefig(os.path.join(RESULT_DIR, \"accuracy_by_sex_modelB.png\"))\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import torchaudio\n",
    "import pandas as pd\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# ── Config ────────────────────────────────\n",
    "DATA_DIR = \"Dataset_2025/Train\"\n",
    "MODEL_PATH = \"best_model_b2.pt\"\n",
    "RESULT_DIR = \"results_modelB2\"\n",
    "FIXED_LEN = 112000  # 7 seconds at 16kHz\n",
    "os.makedirs(RESULT_DIR, exist_ok=True)\n",
    "\n",
    "# ── Log-Mel Transform ─────────────────────\n",
    "mel_transform = torchaudio.transforms.MelSpectrogram(\n",
    "    sample_rate=16000,\n",
    "    n_fft=1024,\n",
    "    hop_length=256,\n",
    "    n_mels=64\n",
    ")\n",
    "db_transform = torchaudio.transforms.AmplitudeToDB()\n",
    "\n",
    "# ── Dataset ───────────────────────────────\n",
    "class SpectrogramDataset(Dataset):\n",
    "    def __init__(self, folder_path):\n",
    "        self.folder_path = folder_path\n",
    "        self.files = sorted([f for f in os.listdir(folder_path) if f.endswith(\".wav\")])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        fname = self.files[idx]\n",
    "        path = os.path.join(self.folder_path, fname)\n",
    "\n",
    "        waveform, sr = torchaudio.load(path)\n",
    "        if waveform.shape[1] < FIXED_LEN:\n",
    "            pad_len = FIXED_LEN - waveform.shape[1]\n",
    "            waveform = F.pad(waveform, (0, pad_len))\n",
    "        else:\n",
    "            waveform = waveform[:, :FIXED_LEN]\n",
    "\n",
    "        mel = mel_transform(waveform)\n",
    "        mel_db = db_transform(mel)\n",
    "\n",
    "        file_id = os.path.splitext(fname)[0]\n",
    "        group, sex = file_id[0], file_id[1]\n",
    "        true_label = int(group)\n",
    "        return mel_db, file_id, true_label, group, sex\n",
    "\n",
    "# ── Evaluation ────────────────────────────\n",
    "def evaluate(model, loader, device):\n",
    "    model.eval()\n",
    "    all_preds, all_trues, meta = [], [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch, ids, labels, groups, sexes in loader:\n",
    "            batch = batch.to(device)\n",
    "            outputs = model(batch)\n",
    "            preds = torch.argmax(outputs, dim=1) + 1\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_trues.extend(labels.numpy())\n",
    "            meta.extend(zip(ids, groups, sexes))\n",
    "\n",
    "    return all_preds, all_trues, meta\n",
    "\n",
    "# ── Plots ─────────────────────────────────\n",
    "def plot_group_sex_accuracy(df):\n",
    "    df[\"group_sex\"] = df[\"group\"] + df[\"sex\"]\n",
    "\n",
    "    combo_acc = df.groupby(\"group_sex\").apply(lambda x: (x.label == x.true).mean()).reset_index(name=\"accuracy\")\n",
    "    plt.figure(figsize=(8, 5))\n",
    "    sns.barplot(data=combo_acc, x=\"group_sex\", y=\"accuracy\", palette=\"viridis\")\n",
    "    plt.title(\"🔍 Accuracy by Group and Sex\")\n",
    "    plt.ylabel(\"Accuracy\")\n",
    "    plt.ylim(0, 1)\n",
    "    plt.grid(axis=\"y\", linestyle=\"--\", alpha=0.4)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(RESULT_DIR, \"accuracy_by_group_sex_modelB.png\"))\n",
    "    plt.close()\n",
    "\n",
    "    group_acc = df.groupby(\"group\").apply(lambda x: (x.label == x.true).mean()).reset_index(name=\"accuracy\")\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    sns.barplot(data=group_acc, x=\"group\", y=\"accuracy\", palette=\"Blues_d\")\n",
    "    plt.title(\"🎯 Accuracy by Group\")\n",
    "    plt.ylabel(\"Accuracy\")\n",
    "    plt.ylim(0, 1)\n",
    "    plt.grid(axis=\"y\", linestyle=\"--\", alpha=0.4)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(RESULT_DIR, \"accuracy_by_group_modelB.png\"))\n",
    "    plt.close()\n",
    "\n",
    "    sex_acc = df.groupby(\"sex\").apply(lambda x: (x.label == x.true).mean()).reset_index(name=\"accuracy\")\n",
    "    plt.figure(figsize=(5, 4))\n",
    "    sns.barplot(data=sex_acc, x=\"sex\", y=\"accuracy\", palette=\"Set2\")\n",
    "    plt.title(\"🧑‍🤝‍🧑 Accuracy by Sex\")\n",
    "    plt.ylabel(\"Accuracy\")\n",
    "    plt.ylim(0, 1)\n",
    "    plt.grid(axis=\"y\", linestyle=\"--\", alpha=0.4)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(RESULT_DIR, \"accuracy_by_sex_modelB.png\"))\n",
    "    plt.close()\n",
    "\n",
    "def plot_confusion_matrix(y_true, y_pred):\n",
    "    cm = confusion_matrix(y_true, y_pred, labels=[1,2,3,4,5])\n",
    "    plt.figure(figsize=(6, 5))\n",
    "    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=[1,2,3,4,5], yticklabels=[1,2,3,4,5])\n",
    "    plt.title(\"Confusion Matrix\")\n",
    "    plt.xlabel(\"Predicted\")\n",
    "    plt.ylabel(\"True\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(RESULT_DIR, \"confusion_matrix_modelB.png\"))\n",
    "    plt.close()\n",
    "\n",
    "# ── Main ─────────────────────────────────\n",
    "def run_full_evaluation():\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "    model = SpectrogramCNN(num_classes=5)\n",
    "    model.load_state_dict(torch.load(MODEL_PATH, map_location=device))\n",
    "    model.to(device)\n",
    "\n",
    "    dataset = SpectrogramDataset(DATA_DIR)\n",
    "    loader = DataLoader(dataset, batch_size=32)\n",
    "\n",
    "    preds, trues, meta = evaluate(model, loader, device)\n",
    "\n",
    "    df = pd.DataFrame(meta, columns=[\"Id\", \"group\", \"sex\"])\n",
    "    df[\"label\"] = preds\n",
    "    df[\"true\"] = trues\n",
    "    df.to_csv(os.path.join(RESULT_DIR, \"detailed_predictions_modelB.csv\"), index=False)\n",
    "    print(f\"✅ Saved predictions to {os.path.join(RESULT_DIR, 'detailed_predictions_modelB.csv')}\")\n",
    "\n",
    "    plot_group_sex_accuracy(df)\n",
    "    plot_confusion_matrix(df[\"true\"], df[\"label\"])\n",
    "    print(f\"📊 All results saved in {RESULT_DIR}\")\n",
    "\n",
    "# ── Run ──────────────────────────────────\n",
    "if __name__ == \"__main__\":\n",
    "    run_full_evaluation()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9e7750d",
   "metadata": {},
   "source": [
    "model b3: this model is to check if the base data can outperform the augumented data or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "304fd310",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Processed 0 files\n",
      "✅ Processed 100 files\n",
      "✅ Processed 200 files\n",
      "✅ Processed 300 files\n",
      "✅ Processed 400 files\n",
      "✅ Processed 500 files\n",
      "✅ Processed 600 files\n",
      "✅ Processed 700 files\n",
      "✅ Processed 800 files\n",
      "✅ Processed 900 files\n",
      "✅ Processed 1000 files\n",
      "✅ Processed 1100 files\n",
      "✅ Processed 1200 files\n",
      "✅ Processed 1300 files\n",
      "✅ Processed 1400 files\n",
      "✅ Processed 1500 files\n",
      "✅ Processed 1600 files\n",
      "✅ Processed 1700 files\n",
      "✅ Processed 1800 files\n",
      "✅ Processed 1900 files\n",
      "✅ Processed 2000 files\n",
      "✅ Processed 2100 files\n",
      "✅ Processed 2200 files\n",
      "✅ Processed 2300 files\n",
      "✅ Processed 2400 files\n",
      "✅ Processed 2500 files\n",
      "✅ Processed 2600 files\n",
      "✅ Processed 2700 files\n",
      "✅ Processed 2800 files\n",
      "✅ Processed 2900 files\n",
      "✅ Processed 3000 files\n",
      "✅ Processed 3100 files\n",
      "\n",
      "✅ All spectrograms saved to: mel_specs\n",
      "📝 Metadata saved to: mel_metadata.csv\n"
     ]
    }
   ],
   "source": [
    "# ── Settings ──────────────────────────────────────────────\n",
    "SOURCE_DIR = \"Dataset_2025/Train\"\n",
    "OUTPUT_DIR = \"mel_specs\"\n",
    "CSV_PATH = \"mel_metadata.csv\"\n",
    "FIXED_LEN = 112000  # 7 seconds @ 16kHz\n",
    "\n",
    "# ── Mel-spectrogram config ────────────────────────────────\n",
    "mel_transform = torchaudio.transforms.MelSpectrogram(\n",
    "    sample_rate=16000,\n",
    "    n_fft=1024,\n",
    "    hop_length=256,\n",
    "    n_mels=64\n",
    ")\n",
    "db_transform = torchaudio.transforms.AmplitudeToDB()\n",
    "\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "metadata = []\n",
    "\n",
    "# ── Loop through .wav files ───────────────────────────────\n",
    "for i, fname in enumerate(sorted(os.listdir(SOURCE_DIR))):\n",
    "    if not fname.endswith(\".wav\"):\n",
    "        continue\n",
    "\n",
    "    path = os.path.join(SOURCE_DIR, fname)\n",
    "    waveform, sr = torchaudio.load(path)\n",
    "    \n",
    "    # print(f\"\\n📁 Processing file: {fname}\")\n",
    "    # print(f\"🎧 Original sample rate: {sr}\")\n",
    "    # print(f\"🔢 Original waveform shape: {waveform.shape}\")\n",
    "\n",
    "    # Pad or truncate to 7s\n",
    "    if waveform.shape[1] < FIXED_LEN:\n",
    "        waveform = F.pad(waveform, (0, FIXED_LEN - waveform.shape[1]))\n",
    "        # print(f\"📏 Padded to: {waveform.shape}\")\n",
    "    else:\n",
    "        waveform = waveform[:, :FIXED_LEN]\n",
    "        # print(f\"📏 Truncated to: {waveform.shape}\")\n",
    "\n",
    "    # Compute spectrogram\n",
    "    mel = mel_transform(waveform)\n",
    "    spec = db_transform(mel)  # log scale\n",
    "    # spec = spec.unsqueeze(0)  # → [1, 64, time]\n",
    "    # print(f\"📊 Mel shape: {mel.shape} → dB shape: {spec.shape}\")\n",
    "\n",
    "    # Save tensor\n",
    "    save_name = fname.replace(\".wav\", \".pt\")\n",
    "    save_path = os.path.join(OUTPUT_DIR, save_name)\n",
    "    torch.save(spec, save_path)\n",
    "    # print(f\"💾 Saved spectrogram to: {save_path}\")\n",
    "\n",
    "    # Extract label\n",
    "    try:\n",
    "        label = int(fname[0]) - 1\n",
    "    except ValueError:\n",
    "        raise ValueError(f\"❌ Failed to extract label from filename: {fname}\")\n",
    "    # print(f\"🏷️ Parsed label: {label}\")\n",
    "\n",
    "    metadata.append((save_name, label))\n",
    "\n",
    "    if i % 100 == 0:\n",
    "        print(f\"✅ Processed {i} files\")\n",
    "\n",
    "# ── Save metadata CSV ─────────────────────────────────────\n",
    "df = pd.DataFrame(metadata, columns=[\"path\", \"label\"])\n",
    "df.to_csv(CSV_PATH, index=False)\n",
    "print(f\"\\n✅ All spectrograms saved to: {OUTPUT_DIR}\")\n",
    "print(f\"📝 Metadata saved to: {CSV_PATH}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8f8e9b4",
   "metadata": {},
   "source": [
    "split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50645c65",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "CSV_PATH = \"mel_metadata.csv\"\n",
    "SPEC_DIR = \"mel_specs\"\n",
    "\n",
    "# ── Load and split metadata ───────────────────────────────\n",
    "df = pd.read_csv(CSV_PATH)\n",
    "train_df, val_df = train_test_split(df, test_size=0.2, stratify=df['label'], random_state=42)\n",
    "\n",
    "# ── Dataset class for loading .pt spectrograms ─────────────\n",
    "class PrecomputedSpectrogramDataset(Dataset):\n",
    "    def __init__(self, dataframe, spec_dir):\n",
    "        self.df = dataframe.reset_index(drop=True)\n",
    "        self.spec_dir = spec_dir\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        spec_path = os.path.join(self.spec_dir, row['path'])\n",
    "        spectrogram = torch.load(spec_path)  # ← Do NOT squeeze here\n",
    "        label = row['label']\n",
    "        return spectrogram, label\n",
    "\n",
    "# ── Create datasets and loaders ────────────────────────────\n",
    "train_dataset = PrecomputedSpectrogramDataset(train_df, spec_dir=SPEC_DIR)\n",
    "val_dataset   = PrecomputedSpectrogramDataset(val_df,   spec_dir=SPEC_DIR)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader   = DataLoader(val_dataset, batch_size=16)\n",
    "\n",
    "# ── Sanity check on data shape ────────────────────────────\n",
    "sample_x, sample_y = next(iter(train_loader))\n",
    "\n",
    "model = SpectrogramCNN(num_classes=5)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3, weight_decay=2e-6)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cf08cdac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🌟 Epoch 1/100\n",
      "📈 Train Loss: 1.7240 | Train Acc: 0.2500\n",
      "📊 Val Loss:   1.5354 | Val Acc:   0.2524\n",
      "💾 Best model saved! (Val Acc: 0.2524)\n",
      "\n",
      "🌟 Epoch 2/100\n",
      "📈 Train Loss: 1.1909 | Train Acc: 0.4889\n",
      "📊 Val Loss:   0.9329 | Val Acc:   0.5994\n",
      "💾 Best model saved! (Val Acc: 0.5994)\n",
      "\n",
      "🌟 Epoch 3/100\n",
      "📈 Train Loss: 0.9289 | Train Acc: 0.6122\n",
      "📊 Val Loss:   0.7615 | Val Acc:   0.6719\n",
      "💾 Best model saved! (Val Acc: 0.6719)\n",
      "\n",
      "🌟 Epoch 4/100\n",
      "📈 Train Loss: 0.6559 | Train Acc: 0.7504\n",
      "📊 Val Loss:   0.5218 | Val Acc:   0.7886\n",
      "💾 Best model saved! (Val Acc: 0.7886)\n",
      "\n",
      "🌟 Epoch 5/100\n",
      "📈 Train Loss: 0.4806 | Train Acc: 0.8144\n",
      "📊 Val Loss:   0.3878 | Val Acc:   0.8549\n",
      "💾 Best model saved! (Val Acc: 0.8549)\n",
      "\n",
      "🌟 Epoch 6/100\n",
      "📈 Train Loss: 0.4111 | Train Acc: 0.8523\n",
      "📊 Val Loss:   0.6025 | Val Acc:   0.7997\n",
      "⏳ No improvement. Patience counter: 1/16\n",
      "\n",
      "🌟 Epoch 7/100\n",
      "📈 Train Loss: 0.3758 | Train Acc: 0.8582\n",
      "📊 Val Loss:   0.4834 | Val Acc:   0.8628\n",
      "💾 Best model saved! (Val Acc: 0.8628)\n",
      "\n",
      "🌟 Epoch 8/100\n",
      "📈 Train Loss: 0.3475 | Train Acc: 0.8756\n",
      "📊 Val Loss:   0.2632 | Val Acc:   0.9006\n",
      "💾 Best model saved! (Val Acc: 0.9006)\n",
      "\n",
      "🌟 Epoch 9/100\n",
      "📈 Train Loss: 0.2234 | Train Acc: 0.9167\n",
      "📊 Val Loss:   0.2423 | Val Acc:   0.9085\n",
      "💾 Best model saved! (Val Acc: 0.9085)\n",
      "\n",
      "🌟 Epoch 10/100\n",
      "📈 Train Loss: 0.2270 | Train Acc: 0.9238\n",
      "📊 Val Loss:   0.2049 | Val Acc:   0.9117\n",
      "💾 Best model saved! (Val Acc: 0.9117)\n",
      "\n",
      "🌟 Epoch 11/100\n",
      "📈 Train Loss: 0.2489 | Train Acc: 0.9103\n",
      "📊 Val Loss:   0.2833 | Val Acc:   0.8927\n",
      "⏳ No improvement. Patience counter: 1/16\n",
      "\n",
      "🌟 Epoch 12/100\n",
      "📈 Train Loss: 0.1839 | Train Acc: 0.9352\n",
      "📊 Val Loss:   0.2116 | Val Acc:   0.9243\n",
      "💾 Best model saved! (Val Acc: 0.9243)\n",
      "\n",
      "🌟 Epoch 13/100\n",
      "📈 Train Loss: 0.2587 | Train Acc: 0.9230\n",
      "📊 Val Loss:   0.2750 | Val Acc:   0.8912\n",
      "⏳ No improvement. Patience counter: 1/16\n",
      "\n",
      "🌟 Epoch 14/100\n",
      "📈 Train Loss: 0.3114 | Train Acc: 0.9001\n",
      "📊 Val Loss:   0.2587 | Val Acc:   0.9085\n",
      "⏳ No improvement. Patience counter: 2/16\n",
      "\n",
      "🌟 Epoch 15/100\n",
      "📈 Train Loss: 0.2180 | Train Acc: 0.9293\n",
      "📊 Val Loss:   0.2799 | Val Acc:   0.9101\n",
      "⏳ No improvement. Patience counter: 3/16\n",
      "\n",
      "🌟 Epoch 16/100\n",
      "📈 Train Loss: 0.2672 | Train Acc: 0.9159\n",
      "📊 Val Loss:   0.5837 | Val Acc:   0.8644\n",
      "⏳ No improvement. Patience counter: 4/16\n",
      "\n",
      "🌟 Epoch 17/100\n",
      "📈 Train Loss: 0.1916 | Train Acc: 0.9376\n",
      "📊 Val Loss:   0.3019 | Val Acc:   0.9274\n",
      "💾 Best model saved! (Val Acc: 0.9274)\n",
      "\n",
      "🌟 Epoch 18/100\n",
      "📈 Train Loss: 0.1274 | Train Acc: 0.9546\n",
      "📊 Val Loss:   0.1828 | Val Acc:   0.9385\n",
      "💾 Best model saved! (Val Acc: 0.9385)\n",
      "\n",
      "🌟 Epoch 19/100\n",
      "📈 Train Loss: 0.1228 | Train Acc: 0.9546\n",
      "📊 Val Loss:   0.2440 | Val Acc:   0.9290\n",
      "⏳ No improvement. Patience counter: 1/16\n",
      "\n",
      "🌟 Epoch 20/100\n",
      "📈 Train Loss: 0.1049 | Train Acc: 0.9688\n",
      "📊 Val Loss:   0.2037 | Val Acc:   0.9416\n",
      "💾 Best model saved! (Val Acc: 0.9416)\n",
      "\n",
      "🌟 Epoch 21/100\n",
      "📈 Train Loss: 0.1271 | Train Acc: 0.9629\n",
      "📊 Val Loss:   0.2734 | Val Acc:   0.9164\n",
      "⏳ No improvement. Patience counter: 1/16\n",
      "\n",
      "🌟 Epoch 22/100\n",
      "📈 Train Loss: 0.1496 | Train Acc: 0.9534\n",
      "📊 Val Loss:   0.3391 | Val Acc:   0.9180\n",
      "⏳ No improvement. Patience counter: 2/16\n",
      "\n",
      "🌟 Epoch 23/100\n",
      "📈 Train Loss: 0.2311 | Train Acc: 0.9348\n",
      "📊 Val Loss:   0.1804 | Val Acc:   0.9543\n",
      "💾 Best model saved! (Val Acc: 0.9543)\n",
      "\n",
      "🌟 Epoch 24/100\n",
      "📈 Train Loss: 0.1225 | Train Acc: 0.9613\n",
      "📊 Val Loss:   0.2201 | Val Acc:   0.9527\n",
      "⏳ No improvement. Patience counter: 1/16\n",
      "\n",
      "🌟 Epoch 25/100\n",
      "📈 Train Loss: 0.1053 | Train Acc: 0.9613\n",
      "📊 Val Loss:   0.2846 | Val Acc:   0.9306\n",
      "⏳ No improvement. Patience counter: 2/16\n",
      "\n",
      "🌟 Epoch 26/100\n",
      "📈 Train Loss: 0.0954 | Train Acc: 0.9696\n",
      "📊 Val Loss:   0.1546 | Val Acc:   0.9495\n",
      "⏳ No improvement. Patience counter: 3/16\n",
      "\n",
      "🌟 Epoch 27/100\n",
      "📈 Train Loss: 0.0852 | Train Acc: 0.9720\n",
      "📊 Val Loss:   0.1831 | Val Acc:   0.9401\n",
      "⏳ No improvement. Patience counter: 4/16\n",
      "\n",
      "🌟 Epoch 28/100\n",
      "📈 Train Loss: 0.1043 | Train Acc: 0.9684\n",
      "📊 Val Loss:   0.2661 | Val Acc:   0.9117\n",
      "⏳ No improvement. Patience counter: 5/16\n",
      "\n",
      "🌟 Epoch 29/100\n",
      "📈 Train Loss: 0.0900 | Train Acc: 0.9684\n",
      "📊 Val Loss:   0.2531 | Val Acc:   0.9432\n",
      "⏳ No improvement. Patience counter: 6/16\n",
      "\n",
      "🌟 Epoch 30/100\n",
      "📈 Train Loss: 0.0689 | Train Acc: 0.9775\n",
      "📊 Val Loss:   0.1604 | Val Acc:   0.9590\n",
      "💾 Best model saved! (Val Acc: 0.9590)\n",
      "\n",
      "🌟 Epoch 31/100\n",
      "📈 Train Loss: 0.0611 | Train Acc: 0.9779\n",
      "📊 Val Loss:   0.1433 | Val Acc:   0.9621\n",
      "💾 Best model saved! (Val Acc: 0.9621)\n",
      "\n",
      "🌟 Epoch 32/100\n",
      "📈 Train Loss: 0.0619 | Train Acc: 0.9850\n",
      "📊 Val Loss:   0.1848 | Val Acc:   0.9558\n",
      "⏳ No improvement. Patience counter: 1/16\n",
      "\n",
      "🌟 Epoch 33/100\n",
      "📈 Train Loss: 0.1796 | Train Acc: 0.9506\n",
      "📊 Val Loss:   0.3341 | Val Acc:   0.8943\n",
      "⏳ No improvement. Patience counter: 2/16\n",
      "\n",
      "🌟 Epoch 34/100\n",
      "📈 Train Loss: 0.1089 | Train Acc: 0.9645\n",
      "📊 Val Loss:   0.2630 | Val Acc:   0.9338\n",
      "⏳ No improvement. Patience counter: 3/16\n",
      "\n",
      "🌟 Epoch 35/100\n",
      "📈 Train Loss: 0.0801 | Train Acc: 0.9743\n",
      "📊 Val Loss:   0.2190 | Val Acc:   0.9338\n",
      "⏳ No improvement. Patience counter: 4/16\n",
      "\n",
      "🌟 Epoch 36/100\n",
      "📈 Train Loss: 0.0860 | Train Acc: 0.9747\n",
      "📊 Val Loss:   0.2237 | Val Acc:   0.9479\n",
      "⏳ No improvement. Patience counter: 5/16\n",
      "\n",
      "🌟 Epoch 37/100\n",
      "📈 Train Loss: 0.1384 | Train Acc: 0.9581\n",
      "📊 Val Loss:   0.5198 | Val Acc:   0.9211\n",
      "⏳ No improvement. Patience counter: 6/16\n",
      "\n",
      "🌟 Epoch 38/100\n",
      "📈 Train Loss: 0.1213 | Train Acc: 0.9637\n",
      "📊 Val Loss:   0.4815 | Val Acc:   0.9369\n",
      "⏳ No improvement. Patience counter: 7/16\n",
      "\n",
      "🌟 Epoch 39/100\n",
      "📈 Train Loss: 0.0639 | Train Acc: 0.9795\n",
      "📊 Val Loss:   0.1505 | Val Acc:   0.9669\n",
      "💾 Best model saved! (Val Acc: 0.9669)\n",
      "\n",
      "🌟 Epoch 40/100\n",
      "📈 Train Loss: 0.0387 | Train Acc: 0.9878\n",
      "📊 Val Loss:   0.3519 | Val Acc:   0.9479\n",
      "⏳ No improvement. Patience counter: 1/16\n",
      "\n",
      "🌟 Epoch 41/100\n",
      "📈 Train Loss: 0.0341 | Train Acc: 0.9878\n",
      "📊 Val Loss:   0.2401 | Val Acc:   0.9479\n",
      "⏳ No improvement. Patience counter: 2/16\n",
      "\n",
      "🌟 Epoch 42/100\n",
      "📈 Train Loss: 0.0756 | Train Acc: 0.9795\n",
      "📊 Val Loss:   0.1421 | Val Acc:   0.9511\n",
      "⏳ No improvement. Patience counter: 3/16\n",
      "\n",
      "🌟 Epoch 43/100\n",
      "📈 Train Loss: 0.0610 | Train Acc: 0.9791\n",
      "📊 Val Loss:   0.3171 | Val Acc:   0.9479\n",
      "⏳ No improvement. Patience counter: 4/16\n",
      "\n",
      "🌟 Epoch 44/100\n",
      "📈 Train Loss: 0.0857 | Train Acc: 0.9743\n",
      "📊 Val Loss:   0.3606 | Val Acc:   0.9322\n",
      "⏳ No improvement. Patience counter: 5/16\n",
      "\n",
      "🌟 Epoch 45/100\n",
      "📈 Train Loss: 0.0432 | Train Acc: 0.9874\n",
      "📊 Val Loss:   0.1736 | Val Acc:   0.9543\n",
      "⏳ No improvement. Patience counter: 6/16\n",
      "\n",
      "🌟 Epoch 46/100\n",
      "📈 Train Loss: 0.0491 | Train Acc: 0.9842\n",
      "📊 Val Loss:   0.1924 | Val Acc:   0.9448\n",
      "⏳ No improvement. Patience counter: 7/16\n",
      "\n",
      "🌟 Epoch 47/100\n",
      "📈 Train Loss: 0.0693 | Train Acc: 0.9858\n",
      "📊 Val Loss:   0.2061 | Val Acc:   0.9448\n",
      "⏳ No improvement. Patience counter: 8/16\n",
      "\n",
      "🌟 Epoch 48/100\n",
      "📈 Train Loss: 0.0568 | Train Acc: 0.9814\n",
      "📊 Val Loss:   0.2946 | Val Acc:   0.9416\n",
      "⏳ No improvement. Patience counter: 9/16\n",
      "\n",
      "🌟 Epoch 49/100\n",
      "📈 Train Loss: 0.0748 | Train Acc: 0.9889\n",
      "📊 Val Loss:   0.1577 | Val Acc:   0.9621\n",
      "⏳ No improvement. Patience counter: 10/16\n",
      "\n",
      "🌟 Epoch 50/100\n",
      "📈 Train Loss: 0.3813 | Train Acc: 0.8839\n",
      "📊 Val Loss:   0.2223 | Val Acc:   0.9432\n",
      "⏳ No improvement. Patience counter: 11/16\n",
      "\n",
      "🌟 Epoch 51/100\n",
      "📈 Train Loss: 0.1381 | Train Acc: 0.9672\n",
      "📊 Val Loss:   0.1114 | Val Acc:   0.9558\n",
      "⏳ No improvement. Patience counter: 12/16\n",
      "\n",
      "🌟 Epoch 52/100\n",
      "📈 Train Loss: 0.0503 | Train Acc: 0.9822\n",
      "📊 Val Loss:   0.1303 | Val Acc:   0.9653\n",
      "⏳ No improvement. Patience counter: 13/16\n",
      "\n",
      "🌟 Epoch 53/100\n",
      "📈 Train Loss: 0.0411 | Train Acc: 0.9866\n",
      "📊 Val Loss:   0.1024 | Val Acc:   0.9700\n",
      "💾 Best model saved! (Val Acc: 0.9700)\n",
      "\n",
      "🌟 Epoch 54/100\n",
      "📈 Train Loss: 0.0221 | Train Acc: 0.9917\n",
      "📊 Val Loss:   0.2370 | Val Acc:   0.9527\n",
      "⏳ No improvement. Patience counter: 1/16\n",
      "\n",
      "🌟 Epoch 55/100\n",
      "📈 Train Loss: 0.0255 | Train Acc: 0.9929\n",
      "📊 Val Loss:   0.0932 | Val Acc:   0.9763\n",
      "💾 Best model saved! (Val Acc: 0.9763)\n",
      "\n",
      "🌟 Epoch 56/100\n",
      "📈 Train Loss: 0.0127 | Train Acc: 0.9957\n",
      "📊 Val Loss:   0.0907 | Val Acc:   0.9685\n",
      "⏳ No improvement. Patience counter: 1/16\n",
      "\n",
      "🌟 Epoch 57/100\n",
      "📈 Train Loss: 0.0056 | Train Acc: 0.9984\n",
      "📊 Val Loss:   0.1379 | Val Acc:   0.9732\n",
      "⏳ No improvement. Patience counter: 2/16\n",
      "\n",
      "🌟 Epoch 58/100\n",
      "📈 Train Loss: 0.0135 | Train Acc: 0.9964\n",
      "📊 Val Loss:   0.1814 | Val Acc:   0.9700\n",
      "⏳ No improvement. Patience counter: 3/16\n",
      "\n",
      "🌟 Epoch 59/100\n",
      "📈 Train Loss: 0.0290 | Train Acc: 0.9949\n",
      "📊 Val Loss:   0.1955 | Val Acc:   0.9527\n",
      "⏳ No improvement. Patience counter: 4/16\n",
      "\n",
      "🌟 Epoch 60/100\n",
      "📈 Train Loss: 0.0879 | Train Acc: 0.9814\n",
      "📊 Val Loss:   0.3115 | Val Acc:   0.9495\n",
      "⏳ No improvement. Patience counter: 5/16\n",
      "\n",
      "🌟 Epoch 61/100\n",
      "📈 Train Loss: 0.1372 | Train Acc: 0.9656\n",
      "📊 Val Loss:   0.1299 | Val Acc:   0.9574\n",
      "⏳ No improvement. Patience counter: 6/16\n",
      "\n",
      "🌟 Epoch 62/100\n",
      "📈 Train Loss: 0.0602 | Train Acc: 0.9826\n",
      "📊 Val Loss:   0.1706 | Val Acc:   0.9495\n",
      "⏳ No improvement. Patience counter: 7/16\n",
      "\n",
      "🌟 Epoch 63/100\n",
      "📈 Train Loss: 0.0820 | Train Acc: 0.9787\n",
      "📊 Val Loss:   0.1216 | Val Acc:   0.9590\n",
      "⏳ No improvement. Patience counter: 8/16\n",
      "\n",
      "🌟 Epoch 64/100\n",
      "📈 Train Loss: 0.0237 | Train Acc: 0.9925\n",
      "📊 Val Loss:   0.1676 | Val Acc:   0.9574\n",
      "⏳ No improvement. Patience counter: 9/16\n",
      "\n",
      "🌟 Epoch 65/100\n",
      "📈 Train Loss: 0.0185 | Train Acc: 0.9953\n",
      "📊 Val Loss:   0.1891 | Val Acc:   0.9669\n",
      "⏳ No improvement. Patience counter: 10/16\n",
      "\n",
      "🌟 Epoch 66/100\n",
      "📈 Train Loss: 0.0098 | Train Acc: 0.9968\n",
      "📊 Val Loss:   0.1036 | Val Acc:   0.9732\n",
      "⏳ No improvement. Patience counter: 11/16\n",
      "\n",
      "🌟 Epoch 67/100\n",
      "📈 Train Loss: 0.0056 | Train Acc: 0.9980\n",
      "📊 Val Loss:   0.1001 | Val Acc:   0.9795\n",
      "💾 Best model saved! (Val Acc: 0.9795)\n",
      "\n",
      "🌟 Epoch 68/100\n",
      "📈 Train Loss: 0.0067 | Train Acc: 0.9988\n",
      "📊 Val Loss:   0.1237 | Val Acc:   0.9842\n",
      "💾 Best model saved! (Val Acc: 0.9842)\n",
      "\n",
      "🌟 Epoch 69/100\n",
      "📈 Train Loss: 0.0034 | Train Acc: 0.9988\n",
      "📊 Val Loss:   0.1346 | Val Acc:   0.9748\n",
      "⏳ No improvement. Patience counter: 1/16\n",
      "\n",
      "🌟 Epoch 70/100\n",
      "📈 Train Loss: 0.0184 | Train Acc: 0.9968\n",
      "📊 Val Loss:   0.1695 | Val Acc:   0.9574\n",
      "⏳ No improvement. Patience counter: 2/16\n",
      "\n",
      "🌟 Epoch 71/100\n",
      "📈 Train Loss: 0.0253 | Train Acc: 0.9913\n",
      "📊 Val Loss:   0.1996 | Val Acc:   0.9590\n",
      "⏳ No improvement. Patience counter: 3/16\n",
      "\n",
      "🌟 Epoch 72/100\n",
      "📈 Train Loss: 0.1976 | Train Acc: 0.9546\n",
      "📊 Val Loss:   1.7549 | Val Acc:   0.7192\n",
      "⏳ No improvement. Patience counter: 4/16\n",
      "\n",
      "🌟 Epoch 73/100\n",
      "📈 Train Loss: 0.1606 | Train Acc: 0.9538\n",
      "📊 Val Loss:   0.2480 | Val Acc:   0.9448\n",
      "⏳ No improvement. Patience counter: 5/16\n",
      "\n",
      "🌟 Epoch 74/100\n",
      "📈 Train Loss: 0.1309 | Train Acc: 0.9664\n",
      "📊 Val Loss:   0.1949 | Val Acc:   0.9416\n",
      "⏳ No improvement. Patience counter: 6/16\n",
      "\n",
      "🌟 Epoch 75/100\n",
      "📈 Train Loss: 0.0590 | Train Acc: 0.9814\n",
      "📊 Val Loss:   0.1541 | Val Acc:   0.9574\n",
      "⏳ No improvement. Patience counter: 7/16\n",
      "\n",
      "🌟 Epoch 76/100\n",
      "📈 Train Loss: 0.0201 | Train Acc: 0.9937\n",
      "📊 Val Loss:   0.1645 | Val Acc:   0.9543\n",
      "⏳ No improvement. Patience counter: 8/16\n",
      "\n",
      "🌟 Epoch 77/100\n",
      "📈 Train Loss: 0.0166 | Train Acc: 0.9945\n",
      "📊 Val Loss:   0.1398 | Val Acc:   0.9669\n",
      "⏳ No improvement. Patience counter: 9/16\n",
      "\n",
      "🌟 Epoch 78/100\n",
      "📈 Train Loss: 0.0124 | Train Acc: 0.9953\n",
      "📊 Val Loss:   0.1822 | Val Acc:   0.9685\n",
      "⏳ No improvement. Patience counter: 10/16\n",
      "\n",
      "🌟 Epoch 79/100\n",
      "📈 Train Loss: 0.0226 | Train Acc: 0.9941\n",
      "📊 Val Loss:   0.1387 | Val Acc:   0.9653\n",
      "⏳ No improvement. Patience counter: 11/16\n",
      "\n",
      "🌟 Epoch 80/100\n",
      "📈 Train Loss: 0.0052 | Train Acc: 0.9984\n",
      "📊 Val Loss:   0.2622 | Val Acc:   0.9669\n",
      "⏳ No improvement. Patience counter: 12/16\n",
      "\n",
      "🌟 Epoch 81/100\n",
      "📈 Train Loss: 0.0170 | Train Acc: 0.9953\n",
      "📊 Val Loss:   0.1565 | Val Acc:   0.9606\n",
      "⏳ No improvement. Patience counter: 13/16\n",
      "\n",
      "🌟 Epoch 82/100\n",
      "📈 Train Loss: 0.0347 | Train Acc: 0.9929\n",
      "📊 Val Loss:   0.1215 | Val Acc:   0.9621\n",
      "⏳ No improvement. Patience counter: 14/16\n",
      "\n",
      "🌟 Epoch 83/100\n",
      "📈 Train Loss: 0.0177 | Train Acc: 0.9941\n",
      "📊 Val Loss:   0.3038 | Val Acc:   0.9511\n",
      "⏳ No improvement. Patience counter: 15/16\n",
      "\n",
      "🌟 Epoch 84/100\n",
      "📈 Train Loss: 0.0309 | Train Acc: 0.9893\n",
      "📊 Val Loss:   0.1847 | Val Acc:   0.9685\n",
      "⏳ No improvement. Patience counter: 16/16\n",
      "🛑 Early stopping triggered.\n",
      "\n",
      "✅ Training complete. Best Val Accuracy: 0.9842\n"
     ]
    }
   ],
   "source": [
    "train_model(\n",
    "    model=model,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    optimizer=optimizer,\n",
    "    criterion=criterion,\n",
    "    device=device,\n",
    "    max_epochs=100,\n",
    "    patience=16,\n",
    "    save_path=\"best_model_b3.pt\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2e789df3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved predictions to submission_b3.csv\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ── Config ────────────────────────────────\n",
    "TEST_WAV_DIR = \"Test set\"\n",
    "MODEL_PATH = \"best_model_b3.pt\"\n",
    "OUTPUT_CSV = \"submission_b3.csv\"\n",
    "FIXED_LEN = 112000  # 7 seconds at 16kHz\n",
    "\n",
    "# ── Log-Mel Transform ─────────────────────\n",
    "mel_transform = torchaudio.transforms.MelSpectrogram(\n",
    "    sample_rate=16000,\n",
    "    n_fft=1024,\n",
    "    hop_length=256,\n",
    "    n_mels=64\n",
    ")\n",
    "db_transform = torchaudio.transforms.AmplitudeToDB()\n",
    "\n",
    "# ── Test Dataset (on-the-fly spectrogram) ─────────────────\n",
    "class TestWavDataset(Dataset):\n",
    "    def __init__(self, folder_path):\n",
    "        self.folder_path = folder_path\n",
    "        self.files = sorted([f for f in os.listdir(folder_path) if f.endswith(\".wav\")])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        fname = self.files[idx]\n",
    "        path = os.path.join(self.folder_path, fname)\n",
    "\n",
    "        waveform, sr = torchaudio.load(path)\n",
    "\n",
    "        # Pad or truncate to 7s\n",
    "        if waveform.shape[1] < FIXED_LEN:\n",
    "            pad_len = FIXED_LEN - waveform.shape[1]\n",
    "            waveform = F.pad(waveform, (0, pad_len))\n",
    "        else:\n",
    "            waveform = waveform[:, :FIXED_LEN]\n",
    "\n",
    "        # Convert to log-mel spectrogram\n",
    "        mel = mel_transform(waveform)\n",
    "        mel_db = db_transform(mel)\n",
    "        # mel_db = mel_db.unsqueeze(0)  # shape: [1, 64, T]\n",
    "\n",
    "        file_id = os.path.splitext(fname)[0]\n",
    "        return mel_db, file_id\n",
    "\n",
    "# ── Run prediction and save submission ─────\n",
    "def run_test():\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    model = SpectrogramCNN(num_classes=5)\n",
    "    model.load_state_dict(torch.load(MODEL_PATH, map_location=device))\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    dataset = TestWavDataset(TEST_WAV_DIR)\n",
    "    loader = DataLoader(dataset, batch_size=32)\n",
    "\n",
    "    predictions = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch, ids in loader:\n",
    "            batch = batch.to(device)\n",
    "            outputs = model(batch)\n",
    "            preds = torch.argmax(outputs, dim=1) + 1  # [0–4] → [1–5]\n",
    "            predictions.extend(zip(ids, preds.cpu().numpy()))\n",
    "\n",
    "    df = pd.DataFrame(predictions, columns=[\"Id\", \"label\"])\n",
    "    df.to_csv(OUTPUT_CSV, index=False)\n",
    "    print(f\"✅ Saved predictions to {OUTPUT_CSV}\")\n",
    "\n",
    "# ── Entry Point ───────────────────────────\n",
    "if __name__ == \"__main__\":\n",
    "    run_test()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "18706787",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved predictions to results_modelB3\\detailed_predictions_modelB.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hiwa\\AppData\\Local\\Temp\\ipykernel_30400\\360063931.py:75: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  combo_acc = df.groupby(\"group_sex\").apply(lambda x: (x.label == x.true).mean()).reset_index(name=\"accuracy\")\n",
      "C:\\Users\\hiwa\\AppData\\Local\\Temp\\ipykernel_30400\\360063931.py:77: FutureWarning: \n",
      "\n",
      "Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.\n",
      "\n",
      "  sns.barplot(data=combo_acc, x=\"group_sex\", y=\"accuracy\", palette=\"viridis\")\n",
      "C:\\Users\\hiwa\\AppData\\Local\\Temp\\ipykernel_30400\\360063931.py:82: UserWarning: Glyph 128269 (\\N{LEFT-POINTING MAGNIFYING GLASS}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "C:\\Users\\hiwa\\AppData\\Local\\Temp\\ipykernel_30400\\360063931.py:83: UserWarning: Glyph 128269 (\\N{LEFT-POINTING MAGNIFYING GLASS}) missing from font(s) DejaVu Sans.\n",
      "  plt.savefig(os.path.join(RESULT_DIR, \"accuracy_by_group_sex_modelB.png\"))\n",
      "C:\\Users\\hiwa\\AppData\\Local\\Temp\\ipykernel_30400\\360063931.py:86: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  group_acc = df.groupby(\"group\").apply(lambda x: (x.label == x.true).mean()).reset_index(name=\"accuracy\")\n",
      "C:\\Users\\hiwa\\AppData\\Local\\Temp\\ipykernel_30400\\360063931.py:88: FutureWarning: \n",
      "\n",
      "Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.\n",
      "\n",
      "  sns.barplot(data=group_acc, x=\"group\", y=\"accuracy\", palette=\"Blues_d\")\n",
      "C:\\Users\\hiwa\\AppData\\Local\\Temp\\ipykernel_30400\\360063931.py:93: UserWarning: Glyph 127919 (\\N{DIRECT HIT}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "C:\\Users\\hiwa\\AppData\\Local\\Temp\\ipykernel_30400\\360063931.py:94: UserWarning: Glyph 127919 (\\N{DIRECT HIT}) missing from font(s) DejaVu Sans.\n",
      "  plt.savefig(os.path.join(RESULT_DIR, \"accuracy_by_group_modelB.png\"))\n",
      "C:\\Users\\hiwa\\AppData\\Local\\Temp\\ipykernel_30400\\360063931.py:97: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  sex_acc = df.groupby(\"sex\").apply(lambda x: (x.label == x.true).mean()).reset_index(name=\"accuracy\")\n",
      "C:\\Users\\hiwa\\AppData\\Local\\Temp\\ipykernel_30400\\360063931.py:99: FutureWarning: \n",
      "\n",
      "Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.\n",
      "\n",
      "  sns.barplot(data=sex_acc, x=\"sex\", y=\"accuracy\", palette=\"Set2\")\n",
      "C:\\Users\\hiwa\\AppData\\Local\\Temp\\ipykernel_30400\\360063931.py:104: UserWarning: Glyph 129489 (\\N{ADULT}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "C:\\Users\\hiwa\\AppData\\Local\\Temp\\ipykernel_30400\\360063931.py:104: UserWarning: Glyph 129309 (\\N{HANDSHAKE}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📊 All results saved in results_modelB3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hiwa\\AppData\\Local\\Temp\\ipykernel_30400\\360063931.py:105: UserWarning: Glyph 129489 (\\N{ADULT}) missing from font(s) DejaVu Sans.\n",
      "  plt.savefig(os.path.join(RESULT_DIR, \"accuracy_by_sex_modelB.png\"))\n",
      "C:\\Users\\hiwa\\AppData\\Local\\Temp\\ipykernel_30400\\360063931.py:105: UserWarning: Glyph 129309 (\\N{HANDSHAKE}) missing from font(s) DejaVu Sans.\n",
      "  plt.savefig(os.path.join(RESULT_DIR, \"accuracy_by_sex_modelB.png\"))\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import torchaudio\n",
    "import pandas as pd\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# ── Config ────────────────────────────────\n",
    "DATA_DIR = \"Dataset_2025/Train\"\n",
    "MODEL_PATH = \"best_model_b3.pt\"\n",
    "RESULT_DIR = \"results_modelB3\"\n",
    "FIXED_LEN = 112000  # 7 seconds at 16kHz\n",
    "os.makedirs(RESULT_DIR, exist_ok=True)\n",
    "\n",
    "# ── Log-Mel Transform ─────────────────────\n",
    "mel_transform = torchaudio.transforms.MelSpectrogram(\n",
    "    sample_rate=16000,\n",
    "    n_fft=1024,\n",
    "    hop_length=256,\n",
    "    n_mels=64\n",
    ")\n",
    "db_transform = torchaudio.transforms.AmplitudeToDB()\n",
    "\n",
    "# ── Dataset ───────────────────────────────\n",
    "class SpectrogramDataset(Dataset):\n",
    "    def __init__(self, folder_path):\n",
    "        self.folder_path = folder_path\n",
    "        self.files = sorted([f for f in os.listdir(folder_path) if f.endswith(\".wav\")])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        fname = self.files[idx]\n",
    "        path = os.path.join(self.folder_path, fname)\n",
    "\n",
    "        waveform, sr = torchaudio.load(path)\n",
    "        if waveform.shape[1] < FIXED_LEN:\n",
    "            pad_len = FIXED_LEN - waveform.shape[1]\n",
    "            waveform = F.pad(waveform, (0, pad_len))\n",
    "        else:\n",
    "            waveform = waveform[:, :FIXED_LEN]\n",
    "\n",
    "        mel = mel_transform(waveform)\n",
    "        mel_db = db_transform(mel)\n",
    "\n",
    "        file_id = os.path.splitext(fname)[0]\n",
    "        group, sex = file_id[0], file_id[1]\n",
    "        true_label = int(group)\n",
    "        return mel_db, file_id, true_label, group, sex\n",
    "\n",
    "# ── Evaluation ────────────────────────────\n",
    "def evaluate(model, loader, device):\n",
    "    model.eval()\n",
    "    all_preds, all_trues, meta = [], [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch, ids, labels, groups, sexes in loader:\n",
    "            batch = batch.to(device)\n",
    "            outputs = model(batch)\n",
    "            preds = torch.argmax(outputs, dim=1) + 1\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_trues.extend(labels.numpy())\n",
    "            meta.extend(zip(ids, groups, sexes))\n",
    "\n",
    "    return all_preds, all_trues, meta\n",
    "\n",
    "# ── Plots ─────────────────────────────────\n",
    "def plot_group_sex_accuracy(df):\n",
    "    df[\"group_sex\"] = df[\"group\"] + df[\"sex\"]\n",
    "\n",
    "    combo_acc = df.groupby(\"group_sex\").apply(lambda x: (x.label == x.true).mean()).reset_index(name=\"accuracy\")\n",
    "    plt.figure(figsize=(8, 5))\n",
    "    sns.barplot(data=combo_acc, x=\"group_sex\", y=\"accuracy\", palette=\"viridis\")\n",
    "    plt.title(\"🔍 Accuracy by Group and Sex\")\n",
    "    plt.ylabel(\"Accuracy\")\n",
    "    plt.ylim(0, 1)\n",
    "    plt.grid(axis=\"y\", linestyle=\"--\", alpha=0.4)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(RESULT_DIR, \"accuracy_by_group_sex_modelB.png\"))\n",
    "    plt.close()\n",
    "\n",
    "    group_acc = df.groupby(\"group\").apply(lambda x: (x.label == x.true).mean()).reset_index(name=\"accuracy\")\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    sns.barplot(data=group_acc, x=\"group\", y=\"accuracy\", palette=\"Blues_d\")\n",
    "    plt.title(\"🎯 Accuracy by Group\")\n",
    "    plt.ylabel(\"Accuracy\")\n",
    "    plt.ylim(0, 1)\n",
    "    plt.grid(axis=\"y\", linestyle=\"--\", alpha=0.4)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(RESULT_DIR, \"accuracy_by_group_modelB.png\"))\n",
    "    plt.close()\n",
    "\n",
    "    sex_acc = df.groupby(\"sex\").apply(lambda x: (x.label == x.true).mean()).reset_index(name=\"accuracy\")\n",
    "    plt.figure(figsize=(5, 4))\n",
    "    sns.barplot(data=sex_acc, x=\"sex\", y=\"accuracy\", palette=\"Set2\")\n",
    "    plt.title(\"🧑‍🤝‍🧑 Accuracy by Sex\")\n",
    "    plt.ylabel(\"Accuracy\")\n",
    "    plt.ylim(0, 1)\n",
    "    plt.grid(axis=\"y\", linestyle=\"--\", alpha=0.4)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(RESULT_DIR, \"accuracy_by_sex_modelB.png\"))\n",
    "    plt.close()\n",
    "\n",
    "def plot_confusion_matrix(y_true, y_pred):\n",
    "    cm = confusion_matrix(y_true, y_pred, labels=[1,2,3,4,5])\n",
    "    plt.figure(figsize=(6, 5))\n",
    "    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=[1,2,3,4,5], yticklabels=[1,2,3,4,5])\n",
    "    plt.title(\"Confusion Matrix\")\n",
    "    plt.xlabel(\"Predicted\")\n",
    "    plt.ylabel(\"True\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(RESULT_DIR, \"confusion_matrix_modelB.png\"))\n",
    "    plt.close()\n",
    "\n",
    "# ── Main ─────────────────────────────────\n",
    "def run_full_evaluation():\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "    model = SpectrogramCNN(num_classes=5)\n",
    "    model.load_state_dict(torch.load(MODEL_PATH, map_location=device))\n",
    "    model.to(device)\n",
    "\n",
    "    dataset = SpectrogramDataset(DATA_DIR)\n",
    "    loader = DataLoader(dataset, batch_size=32)\n",
    "\n",
    "    preds, trues, meta = evaluate(model, loader, device)\n",
    "\n",
    "    df = pd.DataFrame(meta, columns=[\"Id\", \"group\", \"sex\"])\n",
    "    df[\"label\"] = preds\n",
    "    df[\"true\"] = trues\n",
    "    df.to_csv(os.path.join(RESULT_DIR, \"detailed_predictions_modelB.csv\"), index=False)\n",
    "    print(f\"✅ Saved predictions to {os.path.join(RESULT_DIR, 'detailed_predictions_modelB.csv')}\")\n",
    "\n",
    "    plot_group_sex_accuracy(df)\n",
    "    plot_confusion_matrix(df[\"true\"], df[\"label\"])\n",
    "    print(f\"📊 All results saved in {RESULT_DIR}\")\n",
    "\n",
    "# ── Run ──────────────────────────────────\n",
    "if __name__ == \"__main__\":\n",
    "    run_full_evaluation()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "accent-gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
